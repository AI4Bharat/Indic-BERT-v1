{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#download the QA dataset\n",
    "#!kaggle competitions download -c chaii-hindi-and-tamil-question-answering\n",
    "#!unzip train.csv.zip"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import transformers\n",
    "\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer, default_data_collator\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "BASE = Path(\"..\")\n",
    "df = pd.read_csv(BASE / 'train.csv')\n",
    "df_test = pd.read_csv(BASE / 'test.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df.sample(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7a6e807d7</td>\n",
       "      <td>நெல்சன் மண்டேலா (Nelson Rolihlahla Mandela, 18...</td>\n",
       "      <td>நெல்சன் மண்டேலா எத்தனை ஆண்டுகள் சிறையில் இருந்...</td>\n",
       "      <td>27</td>\n",
       "      <td>494</td>\n",
       "      <td>tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>e30235cab</td>\n",
       "      <td>आईबीएम (English: International Business Machin...</td>\n",
       "      <td>आईबीएम कंपनी का मुख्यालय कहाँ पर है?</td>\n",
       "      <td>संयुक्त राष्ट्र के अर्मोंक, न्यू यॉर्क में</td>\n",
       "      <td>176</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>2a75aabcd</td>\n",
       "      <td>Main Page\\n\\nआई एन एस (INS) विक्रमादित्य  (San...</td>\n",
       "      <td>आई एन एस विक्रमादित्य को किस वर्ष भारतीय नौसेन...</td>\n",
       "      <td>16 नवम्बर 2013</td>\n",
       "      <td>279</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>67b7f2604</td>\n",
       "      <td>பூனை பாலூட்டி இனத்தைச் சேர்ந்த ஒரு ஊனுண்ணி ஆகு...</td>\n",
       "      <td>பூனையின் சராசரி ஆயுட்காலம் என்ன?</td>\n",
       "      <td>12-15</td>\n",
       "      <td>3784</td>\n",
       "      <td>tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>9aa6b3e1e</td>\n",
       "      <td>होली (Holi) वसंत ऋतु में मनाया जाने वाला एक मह...</td>\n",
       "      <td>हिंदू धर्म के रंगों के त्यौहार का नाम क्या है?</td>\n",
       "      <td>होली</td>\n",
       "      <td>0</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>4eb7216bf</td>\n",
       "      <td>बसरा इराक का तीसरा सबसे बड़ा नगर एवं महत्वपूर्...</td>\n",
       "      <td>बसरा नगर किस देश में स्थित है?</td>\n",
       "      <td>इराक</td>\n",
       "      <td>5</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>063be4c5a</td>\n",
       "      <td>जयद्रथ-वध मैथिलीशरण गुप्त द्वारा रचित प्रसिद्ध...</td>\n",
       "      <td>'जयद्रथ-वध'' ग्रंथ किसके द्वारा रचित है?</td>\n",
       "      <td>मैथिलीशरण गुप्त</td>\n",
       "      <td>10</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>4dc78516e</td>\n",
       "      <td>एमा चारलॉट डुएरे वॉटसन (जन्म 15 अप्रैल 1990) ए...</td>\n",
       "      <td>एम्मा वाटसन की राष्ट्रीयता क्या है?</td>\n",
       "      <td>ब्रिटिश</td>\n",
       "      <td>48</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>f88f5c088</td>\n",
       "      <td>क्रिकेट एक बल्ले और गेंद का दलीय खेल है जिसकी ...</td>\n",
       "      <td>क्रिकेट के खेल में कितने खिलाड़ी होते है?</td>\n",
       "      <td>ग्यारह</td>\n",
       "      <td>2697</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>3ba572984</td>\n",
       "      <td>टेनिस खेल 2 टीमों के बीच गेंद से खेले जाने वाल...</td>\n",
       "      <td>टेनिस की शुरुआत कहाँ हुई?</td>\n",
       "      <td>फ्रांस</td>\n",
       "      <td>373</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                            context  \\\n",
       "9     7a6e807d7  நெல்சன் மண்டேலா (Nelson Rolihlahla Mandela, 18...   \n",
       "946   e30235cab  आईबीएम (English: International Business Machin...   \n",
       "862   2a75aabcd  Main Page\\n\\nआई एन एस (INS) विक्रमादित्य  (San...   \n",
       "252   67b7f2604  பூனை பாலூட்டி இனத்தைச் சேர்ந்த ஒரு ஊனுண்ணி ஆகு...   \n",
       "969   9aa6b3e1e  होली (Holi) वसंत ऋतु में मनाया जाने वाला एक मह...   \n",
       "462   4eb7216bf  बसरा इराक का तीसरा सबसे बड़ा नगर एवं महत्वपूर्...   \n",
       "1062  063be4c5a  जयद्रथ-वध मैथिलीशरण गुप्त द्वारा रचित प्रसिद्ध...   \n",
       "1035  4dc78516e  एमा चारलॉट डुएरे वॉटसन (जन्म 15 अप्रैल 1990) ए...   \n",
       "460   f88f5c088  क्रिकेट एक बल्ले और गेंद का दलीय खेल है जिसकी ...   \n",
       "614   3ba572984  टेनिस खेल 2 टीमों के बीच गेंद से खेले जाने वाल...   \n",
       "\n",
       "                                               question  \\\n",
       "9     நெல்சன் மண்டேலா எத்தனை ஆண்டுகள் சிறையில் இருந்...   \n",
       "946                आईबीएम कंपनी का मुख्यालय कहाँ पर है?   \n",
       "862   आई एन एस विक्रमादित्य को किस वर्ष भारतीय नौसेन...   \n",
       "252                    பூனையின் சராசரி ஆயுட்காலம் என்ன?   \n",
       "969      हिंदू धर्म के रंगों के त्यौहार का नाम क्या है?   \n",
       "462                      बसरा नगर किस देश में स्थित है?   \n",
       "1062           'जयद्रथ-वध'' ग्रंथ किसके द्वारा रचित है?   \n",
       "1035                एम्मा वाटसन की राष्ट्रीयता क्या है?   \n",
       "460            क्रिकेट के खेल में कितने खिलाड़ी होते है?   \n",
       "614                           टेनिस की शुरुआत कहाँ हुई?   \n",
       "\n",
       "                                     answer_text  answer_start language  \n",
       "9                                             27           494    tamil  \n",
       "946   संयुक्त राष्ट्र के अर्मोंक, न्यू यॉर्क में           176    hindi  \n",
       "862                               16 नवम्बर 2013           279    hindi  \n",
       "252                                        12-15          3784    tamil  \n",
       "969                                         होली             0    hindi  \n",
       "462                                         इराक             5    hindi  \n",
       "1062                             मैथिलीशरण गुप्त            10    hindi  \n",
       "1035                                     ब्रिटिश            48    hindi  \n",
       "460                                       ग्यारह          2697    hindi  \n",
       "614                                       फ्रांस           373    hindi  "
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "dataset = Dataset.from_pandas(df[['id','context', 'question', 'answer_text', 'answer_start']],split='train')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "dataset = dataset.train_test_split(test_size=.2)\n",
    "dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer_text', 'answer_start'],\n",
       "        num_rows: 891\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'context', 'question', 'answer_text', 'answer_start'],\n",
       "        num_rows: 223\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "dataset.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'train': (891, 5), 'test': (223, 5)}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "dataset['train'][385]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'id': 'c18b77850',\n",
       " 'context': 'जापान, एशिया महाद्वीप में स्थित देश है। जापान चार बड़े और अनेक छोटे द्वीपों का एक समूह है। ये द्वीप एशिया के पूर्व समुद्रतट, यानि प्रशांत महासागर में स्थित हैं। इसके निकटतम पड़ोसी चीन, कोरिया तथा रूस हैं। जापान में वहाँ का मूल निवासियों की जनसंख्या ९८.५% है। बाकी 0.5% कोरियाई, 0.4 % चाइनीज़ तथा 0.6% अन्य लोग है। जापानी अपने देश को निप्पॉन कहते हैं, जिसका मतलब सूर्योदय है। जापान की राजधानी टोक्यो है और उसके अन्य बड़े महानगर योकोहामा, ओसाका और क्योटो हैं। बौद्ध धर्म देश का प्रमुख धर्म है और जापान की जनसंख्या में 96% बौद्ध अनुयायी है।[1][2]\\n इतिहास \\n\\nजापानी लोककथाओं के अनुसार विश्व के निर्माता ने सूर्य देवी तथा चन्द्र देवी को भी रचा। फिर उसका पोता क्यूशू द्वीप पर आया और बाद में उनकी संतान होंशू द्वीप पर फैल गए।\\n प्राचीन काल \\nजापान का प्रथम लिखित साक्ष्य ५७ ईस्वी के एक चीनी लेख से मिलता है। इसमें एक ऐसे राजनीतिज्ञ के चीन दौरे का वर्णन है, जो पूर्व के किसी द्वीप से आया था। धीरे-धीरे दोनों देशों के बीच राजनैतिक और सांस्कृतिक सम्बंध स्थापित हुए। उस समय जापानी एक बहुदैविक धर्म का पालन करते थे, जिसमें कई देवता हुआ करते थे। छठी शताब्दी में चीन से होकर बौद्ध धर्म जापान पहुंचा। इसके बाद पुराने धर्म को शिंतो की संज्ञा दी गई जिसका शाब्दिक अर्थ होता है - देवताओं का पंथ। बौद्ध धर्म ने पुरानी मान्यताओं को खत्म नहीं किया पर मुख्य धर्म बौद्ध ही बना रहा। चीन से बौद्ध धर्म का आगमन उसी प्रकार हुआ जिस प्रकार लोग, लिखने की प्रणाली (लिपि) तथा मंदिरो का सांस्कृतिक तथा शैक्षणिक कार्यों के लिए उपयोग।\\nशिंतो मान्यताओं के अनुसार जब कोई राजा मरता है तो उसके बाद का शासक अपना राजधानी पहले से किसी अलग स्थान पर बनाएगा। बौद्ध धर्म के आगमन के बाद इस मान्यता को त्याग दिया गया। ७१० ईस्वी में राजा ने नॉरा नामक एक शहर में अपनी स्थायी राजधानी बनाई। शताब्दी के अन्त तक इसे हाइरा नामक नगर में स्थानान्तरित कर दिया गया जिसे बाद में क्योटो का नाम दिया गया। सन् ९१० में जापानी शासक फूजीवारा ने अपने आप को जापान की राजनैतिक शक्ति से अलग कर लिया। इसके बाद तक जापान की सत्ता का प्रमुख राजनैतिक रूप से जापान से अलग रहा। यह अपने समकालीन भारतीय, यूरोपी तथा इस्लामी क्षेत्रों से पूरी तरह भिन्न था जहाँ सत्ता का प्रमुख ही शक्ति का प्रमुख भी होता था। इस वंश का शासन ग्यारहवीं शताब्दी के अन्त तक रहा। कई लोगों की नजर में यह काल जापानी सभ्यता का स्वर्णकाल था। चीन से सम्पर्क क्षीण पड़ता गया और जापान ने अपना खुद की पहचान बनाई। दसवी सदी में बौद्ध धर्म का मार्ग अपनाया। इसके बाद से जापान ने अपने आप को एक आर्थिक शक्ति के रूप में सुदृढ़ किया और अभी तकनीकी क्षेत्रों में उसका नाम अग्रणी राष्ट्रों में गिना जाता है।\\n भूगोल \\n\\n\\nजापान कई द्वीपों से बना देश है। जापान कोई ६८०० द्वीपों से मिलकर बना है। इनमें से केवल ३४० द्वीप १ वर्ग किलोमीटर से बड़े हैं। जापान को प्रायः चार बड़े द्वीपों का देश कहा जाता है। ये द्वीप हैं - होक्काइडो, होन्शू, शिकोकू तथा क्यूशू। जापानी भूभाग का ७६.२ प्रतिशत भूभाग पहाड़ों से घिरा होने के कारण यहां कृषि योग्य भूमि मात्र १३.४ प्रतिशत है, ३.५ प्रतिशत क्षेत्र में पानी है और ४.६ प्रतिशत भूमि आवासीय उपयोग में है। जापान खाद्यान्नों के मामले में आत्मनिर्भर नहीं है। चारों ओर समुद्र से घिरा होने के बावजूद इसे अपनी जरुरत की २८ प्रतिशत मछलियां बाहर से मंगानी पड़ती है।\\n शासन तथा राजनीति , सरकार \\nयद्यपि ऐसा कहीं लिखा नहीं है पर जापान की राजनैतिक सत्ता का प्रमुख राजा होता है। उसकी शक्तियां सीमित हैं। जापान के संविधान के अनुसार \"राजा देश तथा जनता की एकता का प्रतिनिधित्व करता है\"। संविधान के अनुसार जापान की स्वायत्तता की बागडोर जापान की जनता के हाथों में है।\\n विदेश नीति \\nसैनिक रूप से जापान के सम्बन्ध अमेरिका से सामान्य है।\\n सेना \\nजापान का वर्तमान संविधान इसे दूसरे देशों पर सैनिक अभियान या चढ़ाई करने से मना करता है।\\n अर्थव्यवस्था \\nएक अनुमान के अनुसार जापान विश्व की दूसरी सबसे बड़ी अर्थव्यवस्था है परन्तु जापान की अर्थव्यवस्था स्थिर नहीं है। यहां के लोगो की औसत वार्षिक आय लगभग ५०,०० अमेरिकी डॉलर है जो काफी अधिक है।\\n1868 से, मीजी काल आर्थिक विस्तार का शुभारंभ किया। मीजी शासकों ने मुक्त बाजार अर्थव्यवस्था की अवधारणा को गले लगा लिया और मुक्त उद्यम पूंजीवाद के ब्रिटिश और उत्तरी अमेरिका के रूपों को अपनाया। जापानी विदेश में और पश्चिमी विद्वानों का अध्ययन गए थे जापान में पढ़ाने के काम पर रखा है। आज के उद्यमों के कई समय की स्थापना की थी। जापान एशिया में सबसे विकसित राष्ट्र के रूप में उभरा है।\\n1980 के दशक, समग्र वास्तविक आर्थिक विकास के लिए 1960 से एक \"जापानी\" चमत्कार बुलाया गया है: 1960 के दशक में एक 10% औसत, 1970 के दशक में एक 5% औसत है और 1980 के दशक में एक 4% औसत। विकास जापानी क्या कॉल के दौरान 1990 के दशक में स्पष्ट रूप से धीमा दशक के बाद बड़े पैमाने पर जापानी परिसंपत्ति मूल्य बुलबुला और घरेलू करने के लिए शेयर और अचल संपत्ति बाजार से सट्टा ज्यादतियों मरोड़ इरादा नीतियों के प्रभाव की वजह से खोया। सरकार को आर्थिक छोटी सफलता के साथ मुलाकात की वृद्धि को पुनर्जीवित करने के प्रयासों थे और आगे 2000 में वैश्विक मंदी से प्रभावित। अर्थव्यवस्था 2005 के बाद वसूली के मजबूत संकेत दिखाया. उस वर्ष के लिए जीडीपी विकास 2.8% था।\\n2009 के रूप में, जापान दुनिया में दूसरी सबसे बड़ी अर्थव्यवस्था है पर संयुक्त राज्य अमेरिका के बाद, अमेरिका के आसपास 5 नाममात्र का सकल घरेलू उत्पाद और तीसरे के संदर्भ में खरब डॉलर के बाद संयुक्त राज्य अमेरिका और शक्ति समता जापान के लोक ऋण की खरीद के 192 प्रतिशत के मामले में चीन यह वार्षिक सकल घरेलू उत्पाद, बैंकिंग, बीमा, रियल एस्टेट, खुदरा बिक्री, परिवहन, दूरसंचार और निर्माण की सभी प्रमुख उद्योगों जापान एक बड़े औद्योगिक क्षमता है और सबसे बड़ा की, प्रमुख और सबसे अधिक प्रौद्योगिकी मोटर वाहन, इलेक्ट्रानिक के उत्पादकों उन्नत करने के लिए घर है उपकरण, मशीन टूल्स, इस्पात और पोतों, रसायन, वस्त्र और प्रसंस्कृत खाद्य पदार्थ सकल घरेलू उत्पाद के तीन तिमाहियों के लिए सेवा क्षेत्र खातो।\\n विज्ञान एवं प्रौद्योगिकी \\nजापान पिछले कुछ दशकों से विज्ञान के क्षेत्र में अग्रणी हो गया है। जापान के वैज्ञानिक अनुसंधान के क्षेत्रों, विशेष रूप से प्रौद्योगिकी, मशीनरी और जैव चिकित्सा अनुसंधान के क्षेत्र में अग्रणी देशों में से एक है। लगभग 700,000 शोधकर्ताओं शेयर एक अमेरिका में 94 130 अरब डॉलर का अनुसंधान एवं विकास बजट, विश्व में तीसरी सबसे बड़ी [.] जापान मौलिक वैज्ञानिक अनुसंधान में एक विश्व नेता हैं, होने भी भौतिकी में तेरह नोबेल पुरस्कार विजेताओं का उत्पादन किया, रसायन विज्ञान या चिकित्सा, 95 तीन फील्ड्स पदक 96 और एक गॉस पुरस्कार विजेता\\nजापान के अधिक प्रमुख तकनीकी योगदान के कुछ इलेक्ट्रॉनिक्स, ऑटोमोबाइल के क्षेत्र में, मशीनरी, भूकंप इंजीनियरिंग, औद्योगिक रोबोटिक्स, प्रकाशिकी, रसायन, अर्धचालक और धातुओं पाए जाते हैं। जापान रोबोटिक्स उत्पादन और उपयोग करते हैं, आधे से अधिक रखने (402200 742500 के) दुनिया के औद्योगिक रोबोटों के विनिर्माण के लिए इस्तेमाल किया [98] यह भी QRIO, ASIMO और AIBO का उत्पादन किया। दुनिया में ले जाता है। जापान दुनिया के मोटर वाहन का सबसे बड़ा उत्पादक है 99] [और चार दुनिया की सबसे बड़ी ऑटोमोबाइल पन्द्रह निर्माताओं के लिए घर और आज के रूप में सात दुनिया के बीस सबसे बड़ी अर्धचालक बिक्री नेताओं की\\nजापान एयरोस्पेस एक्सप्लोरेशन एजेंसी (जाक्सा) जापान की अंतरिक्ष एजेंसी है जो अंतरिक्ष और ग्रह अनुसंधान, उड्डयन अनुसंधान आयोजित करता है और रॉकेट और उपग्रह विकसित करता है। यह अंतरराष्ट्रीय अंतरिक्ष स्टेशन में भागीदार है और जापानी प्रयोग मॉड्यूल (Kibo है) किया गया था 2008 में अंतरिक्ष शटल विधानसभा उड़ानों के दौरान अंतरराष्ट्रीय अंतरिक्ष स्टेशन में जोड़ा [100.] यह वीनस जलवायु शुरू की परिक्रमा के रूप में अंतरिक्ष की खोज में की योजना बनाई है (ग्रह 2010 में सी), [101] [102 बुध Magnetospheric परिक्रमा विकासशील] 2013 में शुरू किया जाना है, [103] [104] और 2030 से एक moonbase निर्माण\\n14 सितंबर को, 2007, यह एक एच IIA (मॉडल H2A2022) Tanegashima अंतरिक्ष केंद्र से वाहक रॉकेट को चंद्रमा की कक्षा एक्सप्लोरर \"सेलिन\" (Selenological एण्ड इंजीनियरिंग एक्सप्लोरर) का शुभारंभ किया। सेलिन भी Kaguya के रूप में जाना जाता है, प्राचीन लोककथा बांस कटर की कथा का चंद्र राजकुमारी। Kaguya अपोलो कार्यक्रम के बाद से सबसे बड़ी जांच चंद्र मिशन है। अपने मिशन से चंद्रमा की उत्पत्ति और विकास पर डेटा इकट्ठा है। यह 4 अक्टूबर के बारे में 100 किमी (62 मील) की ऊंचाई पर चंद्रमा की कक्षा में उड़ान] पर एक चंद्र कक्षा में प्रवेश किया।\\n संस्कृति \\n\\nकुछ लोग जापान की संस्कृति को चीन की संस्कृति का ही विस्तार समझते हैं। जापानी लोगो ने कई विधाओं में चीन की संस्कृति का अंधानुकरण किया है। बौद्ध धर्म यहां चीनी तथा कोरियाई भिक्षुओं के माध्यम से पहुंचा। जापान की संस्कृति की सबसे खास बात ये हैं कि यहां के लोग अपनी संस्कृति से बहुत लगाव रखते हैं। मार्च का महीना उत्सवों का महीना होता है। जापानी संगीत उदार है,\\nहोने उपकरणों तराजू, पड़ोसी संस्कृतियों और शैलियों से उधार लिया। Koto जैसे कई उपकरणों, नौवें और दसवें शताब्दियों में पेश किए गए। चौदहवें शताब्दी और लोकप्रिय लोक संगीत से Noh नाटक तारीखों के साथ भाषण, गिटार की तरह shamisen के साथ, सोलहवीं से [144] पश्चिमी शास्त्रीय संगीत, देर से उन्नीसवीं सदी में शुरू की। अब का एक अभिन्न अंग संस्कृति. युद्ध के बाद जापान भारी कर दिया गया है अमेरिकी और यूरोपीय आधुनिक संगीत, जो लोकप्रिय बैंड जम्मू, पॉप संगीत बुलाया के विकास के लिए नेतृत्व किया गया है द्वारा प्रभावित किया।\\nकराओके सबसे व्यापक रूप से सांस्कृतिक गतिविधि अभ्यास है। सांस्कृतिक मामलों एजेंसी द्वारा एक नवंबर 1993 सर्वेक्षण में पाया गया कि अधिक जापानी कराओके गाया था कि वर्ष की तुलना में परंपरागत सांस्कृतिक गतिविधियों में व्यवस्था या चाय समारोह के फूल के रूप में भाग लिया था।\\nजापानी साहित्य की जल्द से जल्द काम दो इतिहास की पुस्तकों में शामिल हैं और Kojiki Nihon Shoki और आठवीं शताब्दी कविता पुस्तक Man\\'yōshū, मान्योशू सभी चीनी अक्षरों में लिखा है। हीयान काल के शुरुआती दिनों में, के रूप में जाना प्रतिलेखन की व्यवस्था काना (हीरागाना और काताकाना) phonograms के रूप में बनाया गया था। बांस कटर की कथा पुराना जापानी कथा माना जाता है हीयान अदालत जीवन के एक खाते. है तकिया सेई Shōnagon द्वारा लिखित पुस्तक के द्वारा दिया है, जबकि लेडी मुरासाकी द्वारा गेंजी की कथा अक्सर दुनिया के पहले उपन्यास के रूप में वर्णित है।\\nईदो अवधि के दौरान, साहित्य इतना chōnin की है कि के रूप में सामुराई शिष्टजन का मैदान नहीं बन गया, साधारण लोग हैं। Yomihon, उदाहरण के लिए, लोकप्रिय बन गया है और पाठकों और ग्रन्थकारिता में इस गहरा बदलाव का पता चलता है [148] मीजी युग पारंपरिक साहित्यिक रूपों, जिसके दौरान जापानी साहित्य पश्चिमी प्रभाव एकीकृत की गिरावट देखी.. Natsume Sōseki और मोरी Ōgai पहली \"जापान के आधुनिक \\'उपन्यासकार, Ryūnosuke Akutagawa, Jun\\'ichirō Tanizaki, Yasunari Kawabata, युकिओ मिशिमा और, द्वारा और अधिक हाल ही में पीछा किया, Haruki Murakami थे। जापान के दो नोबेल पुरस्कार विजेता लेखक-Yasunari Kawabata (1968) और Kenzaburo ँ (1994) है।\\n\\n\\n\\n\\n\\n\\nसाहित्य और धर्म\\nमान्योशू जापान का सबसे पुराना काव्य संकलन है। हाइकु जापान की प्रसिद्ध काव्य विधा रही है तथा मात्सुओ बाशो जापानी हाइकु कविता के प्रसिद्ध कवि हैं।\\n धर्म \\nजापान की 96 प्रतिशत जनता बौद्ध धर्म का अनुसरण करती है। चीन के बाद बौद्ध आबादी वाला जापान सबसे बड़ा देश है। शिंतो धर्म भी यहाँ काफी प्रसिद्ध है, इस धर्म के अधिकतर लोग बौद्ध धर्म का ही पालन करते है। ताओ धर्म, कन्फ्यूशीवाद और बौद्ध धर्म चीन से भी जापानी विश्वासों और सीमा शुल्क को प्रभावित किया है। जापान में धर्म प्रकृति में समधर्मी हो जाता है और प्रथाओं का एक माता पिता, परीक्षा से पहले प्रार्थना छात्रों मना बच्चों के रूप में ऐसी किस्म, में यह परिणाम, जोड़ों एक क्रिश्चियन चर्च पर एक शादी पकड़ होने के बौद्ध मंदिर में आयोजित किया। एक अल्पसंख्यक (2,595,397 या 2.04%) ईसाई धर्म को पेशे के अलावा है, क्योंकि 19 वीं सदी के मध्य, कई धार्मिक संप्रदायों (Shinshūkyō) जापान में Tenrikyo और Aum (शिनरिक्यो या Aleph) जैसे उभरा है।\\n भाषा \\nलगभग ९९% जनता जापानी भाषा बोलती है। \\nलेखन प्रणाली कांजी (चीनी अक्षर) और काना के दो सेट के रूप में अच्छी तरह से लैटिन वर्णमाला और अरबी अंकों का उपयोग करता है। भाषाओं में भी जापान भाषा परिवार का हिस्सा है जो जापानी अंतर्गत आता है, ओकिनावा में बोली जाती हैं, लेकिन कुछ बच्चों को इन भाषाओं के लिए सीख लो. भाषा मरणासन्न केवल कुछ बुजुर्ग होकाईदो में शेष देशी वक्ताओं के साथ है। अधिकांश सार्वजनिक और निजी स्कूलों के छात्रों को दोनों जापानी और अंग्रेजी में पाठ्यक्रमों लेने के लिए आवश्यकता होती है।\\n जनजीवन \\nअपनी जापान यात्रा के बाद निशिकांत ठाकुर लिखते हैं - \\n\\n \"आज जापान में हर व्यक्ति के पास रंगीन टेलीविजन है, करीब 83 प्रतिशत लोगों के पास कार है, 80 प्रतिशत घरों में एयरकंडीशन लगे हैं, 76 प्रतिशत लोगों के पास वीसीआर हैं, 91 प्रतिशत घरों में माइक्रोवेव ओवन हैं और करीब 25 प्रतिशत लोगों के पास पर्सनल कम्प्यूटर हैं। यह है विकास और ऊंचे जीवन स्तर की एक झलक। आम जापानी स्वभाव से शर्मीला, विनम्र, ईमानदार, मेहनती और देशभक्त होता है। यही कारण है कि विकसित देशों की तुलना में जापान में अपराध दर कम है।\" \\nजापान में दुनिया के सबसे ज्यादा बुजुर्ग लोग रहते हैं। जापान तकनीक क्षेत्र में बहुत आगे है\\n खेल-कूद \\n\\nपरंपरागत रूप से, सूमो जापान के राष्ट्रीय खेल माना जाता हैऔर यह जापान में एक लोकप्रिय दर्शक खेल है। जूडो जैसे मार्शल आर्ट, कराटे और आधुनिक Kendo भी व्यापक रूप से प्रचलित है और देश में दर्शकों ने आनंद उठाया. मीजी पुनरुद्धार के बाद कई पश्चिमी खेल जापान में शुरू किया गया और शिक्षा प्रणाली के माध्यम से फैल शुरू किया।\\nजापान में पेशेवर बेसबॉल लीग 1936 में स्थापित किया गया था आज बेसबॉल सबसे लोकप्रिय देश में दर्शक खेल है।. एक के सबसे प्रसिद्ध जापानी बेसबॉल खिलाड़ियों के Ichiro सुजुकी, जो 1994 में जापान की सबसे मूल्यवान प्लेयर अवार्ड, 1995 और 1996 है, अब उत्तर अमेरिकी मेजर लीग बेसबॉल के सिएटल Mariners के लिए खेलता है जीत रही है। उसके पहले, Sadaharu ओह अच्छी तरह से किया गया था जापान के बाहर जाना जाता है, कर अधिक घर मारा अपने समकालीन, हांक हारून, संयुक्त राज्य अमेरिका में किया था की तुलना में अपने कैरियर के दौरान जापान में चलाता है।\\n1992 में जापान प्रोफेशनल फुटबॉल लीग की स्थापना, एसोसिएशन फुटबॉल (सॉकर) के बाद से भी एक विस्तृत निम्नलिखित प्राप्त किया है] जापान। 1981 से इंटरकांटिनेंटल कप के एक स्थल 2004 से था और सह मेजबानी 2002 फीफा विश्व कप दक्षिण के साथ कोरिया. जापान एक सबसे सफल एशिया में फुटबॉल टीमों में से एक है, एशियाई कप जीतने तीन बार.\\nगोल्फ भी जापान, के रूप में लोकप्रिय है सुपर जी.टी. स्पोर्ट्स कार श्रृंखला और निप्पॉन फॉर्मूला फार्मूला रेसिंग के रूप में ऑटो रेसिंग के रूप हैं जुड़वा अँगूठी Motegi था होंडा द्वारा 1997 में पूरा करने के लिए IndyCar लाने के लिए दौड़ जापान.\\nजापान में टोक्यो में 1964 में ग्रीष्मकालीन ओलंपिक की मेजबानी की। जापान के शीतकालीन ओलंपिक की मेजबानी की है दो बार, नागानो में 1998 में और 1972 में साप्पोरो\\n विदेशी संबंधों और सैन्य \\n\\nजापान के पास रखता आर्थिक और सैन्य संबंधों इसके प्रमुख सहयोगी अमेरिका के साथ, अमेरिका और जापान सुरक्षा अपनी विदेश नीति के आधार के रूप में सेवा के साथ गठबंधन 1956 के बाद से संयुक्त राष्ट्र के एक सदस्य राज्य, जापान के रूप में सेवा की है एक गैर 19 साल की कुल के लिए स्थायी सुरक्षा परिषद के सदस्य, 2009 और 2010 के लिए सबसे हाल ही में. यह भी एक G4 सुरक्षा परिषद में स्थायी सदस्यता की मांग देशों की\\nजी -8, APEC, \"आसियान प्लस तीन और पूर्व एशिया शिखर बैठक में एक भागीदार के एक सदस्य के रूप में, जापान सक्रिय रूप से अंतरराष्ट्रीय मामलों में भाग लेता है और दुनिया भर में अपने महत्वपूर्ण सहयोगी के साथ राजनयिक संबंधों को बढ़ाती है। जापान मार्च 2007 और भारत के साथ अक्टूबर 2008 में ऑस्ट्रेलिया के साथ एक सुरक्षा समझौतेयह भी दुनिया की सरकारी विकास सहायता का तीसरा सबसे बड़ा दाता है पर हस्ताक्षर किए। होने के बाद संयुक्त राज्य अमेरिका और यूनाइटेड किंगडम, अमेरिका 2004 में 8,86 अरब डॉलर का दान.  जापान इराक युद्ध करने के लिए गैर लड़नेवाला सैनिक भेजे हैं, लेकिन बाद में इराक से अपनी सेना वापस ले लिया जापानी समुद्री सेल्फ डिफेंस फोर्स. RIMPAC समुद्री अभ्यास में एक नियमित रूप से भागीदार है।\\nजापान ने भी जापानी नागरिकों और अपने परमाणु हथियार और मिसाइल कार्यक्रम के अपने अपहरण पर एक उत्तरी कोरिया के साथ चल रहेविवाद के चेहरे (देखें भी छह पक्षीय वार्ता). कुरील द्वीप विवाद का एक परिणाम के रूप में, जापान तकनीकी रूप से अब भी रूस के साथ युद्ध में कोई मुद्दा सुलझाने संधि पर हस्ताक्षर किए गए थे के बाद से कभी भी है।\\nजापान की सेना द्वारा प्रतिबंधित है अनुच्छेद 9 जापानी संविधान है, जो जापान के युद्ध की घोषणा करने के लिए या अंतर्राष्ट्रीय विवादों के समाधान का एक साधन के रूप में सैन्य बल के प्रयोग का अधिकार त्याग की। जापान के सैन्य रक्षा मंत्रालय द्वारा संचालित है और मुख्य रूप से जापान ग्राउंड सेल्फ डिफेंस फोर्स (JGSDF) के होते हैं, जापान मेरीटाइम सेल्फ डिफेंस (JMSDF) सेना और जापान एयर सेल्फ डिफेंस फोर्स (JASDF). सेना ने हाल ही में आपरेशन किया गया है शांति और जापानी सैनिकों की इराक में तैनाती में प्रयुक्त विश्व युद्ध के द्वितीय के बाद से पहली बार अपने सैन्य उपयोग के विदेशी चिह्नित\\n इन्हें भी देखें \\nजापान का इतिहास\\nजापानी साम्राज्य\\nजापान के क्षेत्र\\nजापान के प्रांत\\nसन्दर्भ\\n\\n बाहरी कड़ियाँ\\n\\n\\nश्रेणी:एशिया के देश\\nश्रेणी:जापान',\n",
       " 'question': 'जापान की राजधानी का नाम क्या है?',\n",
       " 'answer_text': 'टोक्यो',\n",
       " 'answer_start': 392}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert')\n",
    "batch_size = 16"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['sop_classifier.classifier.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.bias', 'predictions.bias', 'predictions.LayerNorm.weight', 'sop_classifier.classifier.bias', 'predictions.decoder.weight', 'predictions.dense.weight', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "tokenizer(\"This is my pc?\", \"I'll be using Indic BERT\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': [2, 255, 54, 1283, 8, 90956, 293, 3, 7922, 398, 13348, 121, 8, 8017, 26, 326, 3814, 8, 121763, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "max_length = 512\n",
    "doc_stride = 128 "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "for i, example in enumerate(dataset['train']):\n",
    "    if len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]) > 384:\n",
    "        break\n",
    "example = dataset['train'][17]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9229"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "len(tokenizer(example[\"question\"], example[\"context\"], max_length=max_length, truncation=\"only_second\")[\"input_ids\"])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    stride=doc_stride\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "[len(x) for x in tokenized_example[\"input_ids\"]]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 445]"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "for x in tokenized_example[\"input_ids\"][:2]:\n",
    "    print(tokenizer.decode(x))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CLS] कतन अमरक उपनवश अमरक करत क हसस थ?[SEP] अमरक करनतकर यदध (1775–1783), जस सयकत रजय म अमरक सवतनतरत यदध य करनतकर यदध भ कह जत ह, गरट बरटन और उसक तरह उततर अमरक उपनवश क बच एक सनय सघरष थ, जसस व उपनवश सवतनतर सयकत रजय अमरक बन। शरआत लडई उततर अमरक महदवप पर हई। सपतवरषय यदध म परजय क बद, बदल क लए आतर फरनस न 1778 म इस नए रषटर स एक सनध क, ज अतत वजय क लए नरणयक सबत हई। अमरक क सवततरत यदध न यरपय उपनवशवद क इतहस म एक नय मड ल दय। उसन अफरक, एशय एव लटन अमरक क रजय क भव सवततरत क लए एक पदधत तयर कर द। इस परकर अमरक क यदध क परणम कवल इतन ह नह हआ क 13 उपनवश मतदश बरटन स अलग ह गए बलक व उपनवश एक तरह स नए रजनतक वचर तथ ससथओ क परयगशल बन गए। पहल बर 16व 17व शतबद क यरपय उपनवशवद और वणजयवद क चनत दकर वजय परपत क। अमरक उपनवश क इगलड क आधपतय स मकत क लए सघरष, इतहस क अनय सघरष स भनन थ। यह सघरष न त गरब स उतपनन असतष क परणम थ और न यह क जनत समतवद वयवसथ स पडत थ। अमरक उपनवश न अपन सवचछदत और वयवहर म सवततरत बनए रखन क लए इगलड सरकर क कठर औपनवशक नत क वरदध सघरष कय थ। अमरक क सवततरत सगरम वशव इतहस क एक महतवपरण घटन ह। करत स परव अमरक क सथत इगलड एव सपन क मधय 1588 ई. म भषण नसनक यदध हआ जसम सपन क परजय हई[SEP]\n",
      "[CLS] कतन अमरक उपनवश अमरक करत क हसस थ?[SEP] जनत समतवद वयवसथ स पडत थ। अमरक उपनवश न अपन सवचछदत और वयवहर म सवततरत बनए रखन क लए इगलड सरकर क कठर औपनवशक नत क वरदध सघरष कय थ। अमरक क सवततरत सगरम वशव इतहस क एक महतवपरण घटन ह। करत स परव अमरक क सथत इगलड एव सपन क मधय 1588 ई. म भषण नसनक यदध हआ जसम सपन क परजय हई और इस क सथ बरटश नसनक शरषठत क सथपन हई और इगलणड न अमरक म अपन औपनवशक बसतय बसई। 1775 ई. तक अमरक म 13 बरटश उपनवश बसए ज चक थ। इन अमरक उपनवश क भगलक दषट स तन भग म वभजत कय ज सकत ह- (१) उततर भग म-मसचसटस, नय हमपशयर, रडस दवप- य पहड और बरफल कषतर थ। अत कष क लयक न थ। इगलड क यह स मछल और लकड परपत हत थ। (२) मधय भग म- नययरक, नयजरस, मरलड आद थ। इन कषतर म शरब और चन जस उदयग थ। (३) दकषण भग म-उततर करलन, दकषण करलन, जरजय, वरजनय आद थ। यह क जलवय गरम थ। अत य परदश खत क लए उपयकत थ। यह मखयत अनज, गनन, तमबक, कपस और बगन फसल क उतपदन हत थ। इन उपनवश म 90% अगरज और 10त% डच, जरमन, फरसस, परतगल आद थ। इस तरह अमरक उपनवश पशचम दनय तथ नई दनय दन क हसस थ। वसतत पशचम दनय क हसस इसलए क यह आकर बसन वल लग यरप क वभनन परदश जस बरटन, जरमन, फरस, आयरलड आद स आए[SEP]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    stride=doc_stride\n",
    ")\n",
    "print(tokenized_example[\"offset_mapping\"][0][:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 0), (0, 1), (2, 4), (5, 10), (11, 12), (13, 16), (16, 17), (18, 21), (21, 26), (27, 28), (29, 36), (37, 39), (40, 44), (45, 46), (47, 49), (50, 51), (0, 0), (0, 4), (5, 6), (7, 12), (13, 18), (19, 21), (22, 23), (24, 25), (25, 27), (27, 29), (29, 31), (31, 32), (32, 35), (35, 37), (37, 38), (38, 42), (43, 47), (48, 51), (51, 55), (56, 57), (57, 59), (61, 66), (67, 68), (69, 71), (72, 75), (76, 79), (79, 80), (81, 83), (84, 85), (86, 87), (87, 89), (90, 95), (96, 101), (102, 104), (105, 106), (107, 108), (108, 110), (111, 114), (115, 119), (120, 122), (123, 124), (124, 128), (129, 130), (130, 134), (135, 138), (138, 141), (141, 144), (144, 145), (146, 151), (151, 154), (155, 157), (157, 162), (163, 164), (165, 168), (168, 169), (170, 173), (175, 177), (178, 182), (182, 185), (185, 189), (190, 191), (191, 193), (194, 196), (197, 198), (198, 200), (201, 202), (202, 206), (206, 207), (208, 210), (211, 214), (214, 215), (216, 219), (219, 221), (222, 225), (226, 229), (229, 233), (234, 237), (237, 241), (242, 243), (243, 248), (249, 250), (251, 254), (255, 256), (256, 260)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "first_token_id = tokenized_example[\"input_ids\"][0][77]\n",
    "offsets = tokenized_example[\"offset_mapping\"][0][77]\n",
    "print(tokenizer.convert_ids_to_tokens([first_token_id])[0], example[\"question\"][offsets[0]:offsets[1]])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "▁स \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "sequence_ids = tokenized_example.sequence_ids()\n",
    "print(sequence_ids)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "answers = example[\"answer_text\"]\n",
    "start_char = example[\"answer_start\"]\n",
    "end_char = start_char + len(example[\"answer_text\"][0])\n",
    "\n",
    "# Start token index of the current span in the text.\n",
    "token_start_index = 0\n",
    "while sequence_ids[token_start_index] != 1:\n",
    "    token_start_index += 1\n",
    "\n",
    "# End token index of the current span in the text.\n",
    "token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n",
    "while sequence_ids[token_end_index] != 1:\n",
    "    token_end_index -= 1\n",
    "\n",
    "# Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "offsets = tokenized_example[\"offset_mapping\"][0]\n",
    "if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "    # Move the token_start_index and token_end_index to the two ends of the answer.\n",
    "    # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "        token_start_index += 1\n",
    "    start_position = token_start_index - 1\n",
    "    while offsets[token_end_index][1] >= end_char:\n",
    "        token_end_index -= 1\n",
    "    end_position = token_end_index + 1\n",
    "    print(start_position, end_position)\n",
    "else:\n",
    "    print(\"The answer is not in this feature.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "64 64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "def prepare_train_features(examples):\n",
    "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
    "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
    "    # left whitespace\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answer_text\"][sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if len(examples[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = examples[\"answer_start\"][0]\n",
    "            end_char = start_char + len(examples[\"answer_text\"][0])\n",
    "\n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "features = prepare_train_features(dataset['train'][:5])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "tokenized_datasets = dataset.map(prepare_train_features, batched=True, remove_columns=dataset['train'].column_names)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b6a0d8d31041ae9c55a52b767ce89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58be7f23ebe04acd85ec9e57901e54db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained('ai4bharat/indic-bert')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertForQuestionAnswering: ['sop_classifier.classifier.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.bias', 'predictions.bias', 'predictions.LayerNorm.weight', 'sop_classifier.classifier.bias', 'predictions.decoder.weight', 'predictions.dense.weight', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForQuestionAnswering were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "model_name = \"ai4bharat/indic-bert\".split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"chaii-base\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "data_collator = default_data_collator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}